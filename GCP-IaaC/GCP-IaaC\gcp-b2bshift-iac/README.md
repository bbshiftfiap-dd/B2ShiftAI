# ================================================
# README.MD - B2BSHIFT PLATFORM IaC
# Documenta√ß√£o da Infraestrutura como C√≥digo
# ================================================

# üöÄ B2BShift Platform - Infrastructure as Code

Este reposit√≥rio cont√©m os scripts Terraform para provisionar toda a infraestrutura da plataforma B2BShift no Google Cloud Platform (GCP).

## üìã Arquitetura da Solu√ß√£o

A plataforma B2BShift √© uma solu√ß√£o completa de analytics e data engineering que inclui:

### üóÇÔ∏è Data Lake (Cloud Storage)
- **Landing Zone**: Dados brutos rec√©m-chegados
- **Raw Zone**: Dados n√£o processados
- **Trusted Zone**: Dados limpos e validados  
- **Refined Zone**: Dados agregados e otimizados
- **Archive Zone**: Dados hist√≥ricos

### üè¢ Data Warehouse (BigQuery)
- **Raw Dataset**: Dados brutos das fontes (Sales Proposals, Customer Stats, Contracts, NPS, Support Tickets, External Data)
- **Trusted Dataset**: Dados limpos e estruturados com valida√ß√µes aplicadas
- **Refined Dataset**: Star Schema otimizado com dimens√µes e fatos para analytics
- **Analytics Dataset**: M√©tricas agregadas, KPIs e vis√µes 360 dos clientes

### ‚ö° Processamento de Dados
- **Dataflow**: ETL/ELT em tempo real e batch
- **Dataproc**: Processamento big data com Spark/Hadoop
- **Pub/Sub**: Streaming de dados em tempo real

### ü§ñ Machine Learning (Vertex AI)
- **Datasets**: Conjuntos de dados para treinamento
- **Endpoints**: Deploy de modelos em produ√ß√£o
- **Feature Store**: Armazenamento de features
- **Notebooks**: Ambiente de desenvolvimento ML

### üîÑ Orquestra√ß√£o (Cloud Composer/Airflow)
- **DAGs**: Workflows automatizados
- **Scheduling**: Execu√ß√£o programada de pipelines
- **Monitoring**: Monitoramento de execu√ß√µes

### üìä Governan√ßa (DataPlex)
- **Discovery**: Descoberta autom√°tica de dados
- **Quality**: Verifica√ß√£o de qualidade dos dados
- **Cataloging**: Cataloga√ß√£o e metadados

## üìÅ Estrutura dos Arquivos

```
gcp-b2bshift-iac/
‚îú‚îÄ‚îÄ provider.tf              # Configura√ß√£o do provider GCP
‚îú‚îÄ‚îÄ variables.tf             # Defini√ß√£o de vari√°veis
‚îú‚îÄ‚îÄ storage.tf               # Buckets do Data Lake
‚îú‚îÄ‚îÄ bigquery.tf              # Data Warehouse e tabelas
‚îú‚îÄ‚îÄ dataflow.tf              # Jobs de ETL/ELT
‚îú‚îÄ‚îÄ dataproc.tf              # Cluster Spark/Hadoop
‚îú‚îÄ‚îÄ vertex_ai.tf             # Infraestrutura de ML
‚îú‚îÄ‚îÄ composer.tf              # Orquestra√ß√£o Airflow
‚îú‚îÄ‚îÄ dataplex.tf              # Governan√ßa de dados
‚îú‚îÄ‚îÄ outputs.tf               # Outputs dos recursos
‚îú‚îÄ‚îÄ terraform.tfvars.example # Exemplo de vari√°veis
‚îî‚îÄ‚îÄ README.md                # Esta documenta√ß√£o
```

## üõ†Ô∏è Pr√©-requisitos

1. **Terraform** >= 1.3.0
2. **Google Cloud SDK** configurado
3. **Projeto GCP** com billing habilitado
4. **Permiss√µes** de Editor/Owner no projeto

## ‚öôÔ∏è Configura√ß√£o Inicial

### 1. Clone e Configure
```bash
# Navegue at√© o diret√≥rio
cd gcp-b2bshift-iac

# Copie o arquivo de exemplo
cp terraform.tfvars.example terraform.tfvars

# Edite com seus valores
# Altere project_id, region, etc.
```

### 2. Autentica√ß√£o no GCP
```bash
# Login no GCP
gcloud auth login

# Configure o projeto padr√£o
gcloud config set project SEU-PROJECT-ID

# Configure credenciais para Terraform
gcloud auth application-default login
```

### 3. Inicializa√ß√£o do Terraform
```bash
# Inicialize o Terraform
terraform init

# Valide a configura√ß√£o
terraform validate

# Visualize o plano
terraform plan
```

## üöÄ Execu√ß√£o

### Deploy Completo
```bash
# Execute o deploy
terraform apply

# Confirme digitando 'yes'
```

### Deploy por M√≥dulos (Recomendado)
```bash
# 1. APIs e configura√ß√µes b√°sicas
terraform apply -target=google_project_service.required_apis

# 2. Storage
terraform apply -target=module.storage

# 3. BigQuery
terraform apply -target=module.bigquery

# 4. Processamento (Dataflow + Dataproc)
terraform apply -target=module.dataflow
terraform apply -target=module.dataproc

# 5. ML (Vertex AI)
terraform apply -target=module.vertex_ai

# 6. Orquestra√ß√£o (Composer)
terraform apply -target=module.composer

# 7. Governan√ßa (DataPlex)
terraform apply -target=module.dataplex
```

## üìä Recursos Criados

### Storage (5 buckets)
- landing-zone-{project}-{env}
- raw-zone-{project}-{env}
- trusted-zone-{project}-{env}
- refined-zone-{project}-{env}
- archive-zone-{project}-{env}

### BigQuery (4 datasets + tabelas)
- b2bshift_raw
- b2bshift_trusted
- b2bshift_refined
- b2bshift_analytics

### Processamento
- 3 jobs Dataflow configurados
- 1 cluster Dataproc com autoscaling
- 1 t√≥pico Pub/Sub

### Machine Learning
- 2 datasets Vertex AI
- 1 endpoint para deploy
- 1 feature store
- 1 notebook instance

### Orquestra√ß√£o
- 1 ambiente Composer/Airflow
- 1 Cloud Function para triggers
- 1 Cloud Scheduler

### Governan√ßa
- 1 DataPlex Lake
- 2 DataPlex Zones
- Multiple assets configurados

## üîç Monitoramento

Ap√≥s o deploy, acesse:

```bash
# URLs de acesso r√°pido
terraform output quick_access_urls
```

- **BigQuery Console**: Visualizar dados e executar queries
- **Dataflow Console**: Monitorar jobs de ETL
- **Dataproc Console**: Gerenciar clusters Spark
- **Vertex AI Console**: Treinar e implantar modelos
- **Composer Console**: Visualizar DAGs do Airflow
- **DataPlex Console**: Governan√ßa e qualidade

## üí∞ Custos Estimados

| Servi√ßo | Custo Mensal (USD) | Observa√ß√µes |
|---------|-------------------|-------------|
| BigQuery | $50-200 | Depende do volume de dados |
| Cloud Storage | $20-50 | Depende do armazenamento |
| Dataproc | $100-300 | Cluster sempre ativo |
| Composer | $150-250 | Ambiente gerenciado |
| Vertex AI | $50-150 | Depende do uso de ML |
| **Total** | **$370-950** | Estimativa para ambiente dev |

## üßπ Limpeza

```bash
# Para destruir toda a infraestrutura
terraform destroy

# Confirme digitando 'yes'
```

‚ö†Ô∏è **ATEN√á√ÉO**: Isso ir√° deletar TODOS os dados e recursos!

## üìã Checklist de Deploy

- [ ] Projeto GCP criado e configurado
- [ ] Billing habilitado
- [ ] Terraform instalado
- [ ] Vari√°veis configuradas em terraform.tfvars
- [ ] `terraform init` executado
- [ ] `terraform plan` validado
- [ ] `terraform apply` executado
- [ ] Outputs verificados
- [ ] Acesso aos consoles testado

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -am 'Add: nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## üìû Suporte

Para d√∫vidas ou suporte:
- **Email**: data-team@b2bshift.com
- **Slack**: #data-engineering
- **Wiki**: [Link para documenta√ß√£o interna]

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

üöÄ **Happy Data Engineering!** üöÄ
