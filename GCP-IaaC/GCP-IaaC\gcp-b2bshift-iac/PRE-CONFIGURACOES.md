# ================================================
# PRÃ‰-CONFIGURAÃ‡Ã•ES NECESSÃRIAS - B2BSHIFT
# O que configurar ANTES de executar o Terraform
# ================================================

## ğŸš¨ CONFIGURAÃ‡Ã•ES OBRIGATÃ“RIAS NO CONSOLE GCP

### 1. ğŸ” AUTENTICAÃ‡ÃƒO E PERMISSÃ•ES

#### A. Configure suas credenciais:
```powershell
# Login no GCP
gcloud auth login

# Configure o projeto
gcloud config set project b2bshift

# Configure credenciais para o Terraform
gcloud auth application-default login
```

#### B. Verifique se sua conta tem as seguintes permissÃµes no projeto `b2bshift`:
- âœ… **Project Editor** OU **Owner**
- âœ… **Service Account Admin**
- âœ… **Security Admin** 
- âœ… **BigQuery Admin**
- âœ… **Storage Admin**
- âœ… **Compute Admin**

### 2. ğŸ”§ BILLING E APIS

#### A. Habilite o Billing:
- Acesse: https://console.cloud.google.com/billing
- Associe uma conta de billing ao projeto `b2bshift`

#### B. As APIs serÃ£o habilitadas automaticamente pelo Terraform, mas vocÃª pode habilitar manualmente se preferir:
```powershell
gcloud services enable compute.googleapis.com
gcloud services enable storage-api.googleapis.com
gcloud services enable bigquery.googleapis.com
gcloud services enable dataflow.googleapis.com
gcloud services enable dataproc.googleapis.com
gcloud services enable composer.googleapis.com
gcloud services enable aiplatform.googleapis.com
gcloud services enable dataplex.googleapis.com
gcloud services enable cloudbuild.googleapis.com
gcloud services enable iam.googleapis.com
```

## ğŸ¤– SERVICE ACCOUNTS CRIADAS AUTOMATICAMENTE

O Terraform criarÃ¡ automaticamente os seguintes Service Accounts:

### 1. **Dataflow Service Account**
- **Nome**: `b2bshift-dataflow-sa@b2bshift.iam.gserviceaccount.com`
- **PermissÃµes**: dataflow.worker, bigquery.dataEditor, storage.objectAdmin
- **Uso**: Jobs de ETL/ELT no Dataflow

### 2. **Dataproc Service Account**  
- **Nome**: `b2bshift-dataproc-sa@b2bshift.iam.gserviceaccount.com`
- **PermissÃµes**: dataproc.worker, bigquery.dataEditor, storage.objectAdmin
- **Uso**: Cluster Spark/Hadoop

### 3. **Vertex AI Service Account**
- **Nome**: `b2bshift-vertex-ai-sa@b2bshift.iam.gserviceaccount.com`
- **PermissÃµes**: aiplatform.user, bigquery.dataViewer, ml.admin
- **Uso**: Machine Learning pipelines

### 4. **Composer Service Account**
- **Nome**: `b2bshift-composer-sa@b2bshift.iam.gserviceaccount.com`
- **PermissÃµes**: composer.worker, bigquery.dataEditor, dataflow.admin
- **Uso**: OrquestraÃ§Ã£o Airflow

### 5. **DataPlex Service Account**
- **Nome**: `b2bshift-dataplex-sa@b2bshift.iam.gserviceaccount.com`
- **PermissÃµes**: dataplex.editor, bigquery.dataViewer
- **Uso**: GovernanÃ§a de dados

## âš ï¸ CONFIGURAÃ‡Ã•ES MANUAIS NECESSÃRIAS

### 1. ğŸ“§ EMAILS NAS TABELAS BIGQUERY
**âš ï¸ IMPORTANTE**: VocÃª precisa alterar os emails nos arquivos Terraform:

No arquivo `bigquery.tf`, procure e substitua:

```hcl
# ENCONTRE estas linhas (aproximadamente linha 45-55):
access {
  role          = "OWNER"
  user_by_email = "data-team@b2bshift.com" # âš ï¸ SUBSTITUA pelo seu email
}

access {
  role   = "READER"
  group_by_email = "analytics-team@b2bshift.com" # âš ï¸ SUBSTITUA pelo grupo/email
}
```

**SUBSTITUA POR:**
```hcl
access {
  role          = "OWNER"
  user_by_email = "SEU-EMAIL@GMAIL.COM" # âš ï¸ Coloque seu email real
}

# Remova ou substitua o group_by_email se nÃ£o tiver um grupo
```

### 2. ğŸ“ STORAGE BUCKETS - Scripts e Templates
VocÃª precisarÃ¡ fazer upload de alguns arquivos posteriormente:

#### Bucket: `b2bshift-scripts-b2bshift-dev`
- ğŸ“‚ `transforms/csv_transform.js` (funÃ§Ã£o JavaScript para Dataflow)
- ğŸ“‚ `dataplex/data_quality_check.py` (script Python qualidade)
- ğŸ“‚ `dataplex/schema_discovery.py` (script descoberta)
- ğŸ“‚ `python/customer_analytics.py` (PySpark analytics)
- ğŸ“‚ `jars/b2bshift-etl.jar` (JAR Spark/Scala)

### 3. ğŸ”§ CLOUD FUNCTION ZIP
Para o trigger de DAGs:
- ğŸ“‚ `cloud-functions/dag-trigger.zip` (cÃ³digo da Cloud Function)

## ğŸš€ ORDEM DE EXECUÃ‡ÃƒO RECOMENDADA

### Passo 1: ConfiguraÃ§Ã£o Inicial
```powershell
# 1. AutenticaÃ§Ã£o
gcloud auth login
gcloud config set project b2bshift
gcloud auth application-default login

# 2. Verificar projeto ativo
gcloud config get-value project
# Deve retornar: b2bshift
```

### Passo 2: Terraform
```powershell
# 1. Inicializar
terraform init

# 2. Validar
terraform validate

# 3. Planejar
terraform plan

# 4. Aplicar (CUIDADO: Vai criar recursos que custam dinheiro!)
terraform apply
```

### Passo 3: ValidaÃ§Ã£o
```powershell
# Executar script de validaÃ§Ã£o
.\validate.ps1
```

## ğŸ’° CUSTOS ESTIMADOS

| ServiÃ§o | Custo/Dia (USD) | ObservaÃ§Ãµes |
|---------|-----------------|-------------|
| Dataproc Cluster | $8-12 | Cluster sempre ativo |
| Composer Environment | $6-8 | Ambiente gerenciado |
| BigQuery | $1-3 | Depende do volume |
| Cloud Storage | $0.50 | Buckets vazios inicialmente |
| Vertex AI | $2-5 | Notebooks + feature store |
| **TOTAL** | **$17-28/dia** | **â‰ˆ $500-850/mÃªs** |

âš ï¸ **IMPORTANTE**: Execute `terraform destroy` apÃ³s os testes para evitar custos!

## ğŸ” VERIFICAÃ‡Ã•ES PRÃ‰-EXECUÃ‡ÃƒO

Antes de executar `terraform apply`, verifique:

- [ ] âœ… Projeto `b2bshift` existe e tem billing ativo
- [ ] âœ… VocÃª tem permissÃµes de Owner/Editor no projeto
- [ ] âœ… gcloud estÃ¡ autenticado e configurado
- [ ] âœ… Emails atualizados no `bigquery.tf`
- [ ] âœ… terraform.tfvars configurado
- [ ] âœ… Terraform instalado e funcionando

## ğŸ†˜ TROUBLESHOOTING

### Erro: "Permission denied"
```powershell
# Re-autentique
gcloud auth revoke --all
gcloud auth login
gcloud auth application-default login
```

### Erro: "Billing account not found"
- Acesse: https://console.cloud.google.com/billing
- Associe uma conta de billing ao projeto

### Erro: "API not enabled"
- O Terraform habilitarÃ¡ automaticamente
- Ou execute manualmente os comandos de habilitaÃ§Ã£o acima

---

ğŸ“ **DÃºvidas?** Consulte os logs detalhados e a documentaÃ§Ã£o nos arquivos README.md
